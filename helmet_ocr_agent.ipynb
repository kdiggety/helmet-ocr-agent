{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helmet OCR Agent Notebook\n",
    "This notebook captures images, simulates extracting sticker regions, performs OCR, and summarizes helmet sizes and purchase years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "NUM_PHOTOS = 5\n",
    "CAMERA_INDEX = 0\n",
    "PHOTO_DIR = \"photos\"\n",
    "os.makedirs(PHOTO_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Capture Images\n",
    "def capture_images():\n",
    "    cam = cv2.VideoCapture(CAMERA_INDEX)\n",
    "    for i in range(NUM_PHOTOS):\n",
    "        ret, frame = cam.read()\n",
    "        if ret:\n",
    "            cv2.imwrite(f\"{PHOTO_DIR}/photo_{i}.jpg\", frame)\n",
    "    cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Simulate cropping helmet stickers\n",
    "def extract_sticker_regions(image):\n",
    "    h, w, _ = image.shape\n",
    "    crops = [\n",
    "        image[int(h*0.7):h, int(w*0.05):int(w*0.25)],\n",
    "        image[int(h*0.7):h, int(w*0.35):int(w*0.55)]\n",
    "    ]\n",
    "    return crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: OCR on cropped sticker\n",
    "def extract_size_year(crop_img):\n",
    "    gray = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "    pil_img = Image.fromarray(thresh)\n",
    "    text = pytesseract.image_to_string(pil_img)\n",
    "    match = re.search(r'(XS|S|M|L|XL|XXL)[\\s\\-]*(20\\d{2})', text)\n",
    "    return match.groups() if match else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Full process + summary table\n",
    "def run_pipeline():\n",
    "    summary = defaultdict(int)\n",
    "    for i in range(NUM_PHOTOS):\n",
    "        path = f\"{PHOTO_DIR}/photo_{i}.jpg\"\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        crops = extract_sticker_regions(img)\n",
    "        for crop in crops:\n",
    "            size, year = extract_size_year(crop)\n",
    "            if size and year:\n",
    "                summary[(size, year)] += 1\n",
    "    df = pd.DataFrame([{'Size': s, 'Year': y, 'Count': c} for (s, y), c in summary.items()])\n",
    "    return df.sort_values(['Year', 'Size'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
